# Respuestas de Reflexión

## 1. ¿Cómo te ayuda PySpark a manejar grandes volúmenes de datos?

PySpark permite procesar grandes cantidades de datos de manera eficiente gracias a su arquitectura distribuida. A diferencia de Pandas que trabaja memoria en una sola máquina, PySpark divide el procesamiento en varios nodos o núcleos, lo cual resulta en un mejor rendimiento y mayor escalabilidad cuando se trabaja con cantidades de datos masivas. 

## 2. ¿Qué ventajas encontraste al usar PySpark para realizar análisis de datos en comparación con otras herramientas que conoces?

Las principales ventajas que tiene PySpark en comparación a otras herramientas son: 
- **Escalabilidad:** Puede trabajar con terabytes de datos sin necesidad de cargarlos todos en memoria.
- **Velocidad:** Optimiza el procesamiento usando ejecución distribuida.
- **Funcionalidades SQL y de DataFrame:** Permite usar tanto consultas SQL como operaciones con DataFrames de manera fluida.

En comparación con herramientas como pandas, PySpark es más adecuado para análisis de big data.

## 3. ¿Qué otras operaciones de análisis podrías realizar con el nuevo conjunto de datos?

Algunas otras operaciones que se podrían implementar son:

- Obtener los 5 países con mayor número de usuarios con una comida favorita específica.
- Calcular la moda del número de la suerte por país.
- Detectar nicknames duplicados o más frecuentes.
- Realizar agrupaciones más complejas, como combinaciones de país y comida favorita.
- Visualizar la distribución del número de la suerte.

